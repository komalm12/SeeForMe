SeeForMe â€“ Assistive App for Visually Impaired Individuals

A mobile application designed to empower visually impaired users with real-time environment interaction using AI, machine learning, and accessibility-first UI.
ğŸš€ Features
Currency Recognition â€“ Identify currency notes instantly.

Object Detection â€“ Recognize surrounding objects using AI.

Color Detection â€“ Detect and speak out color names in real time.

Document Scanning & Reading â€“ Scan printed text and read it aloud using Text-to-Speech (TTS).

Gesture-based Navigation â€“ Easy controls for users without needing precise taps.

Voice Guidance â€“ Step-by-step speech feedback throughout the app.

Offline Support â€“ Core features available without internet.

ğŸ› ï¸ Tech Stack
Flutter (Frontend)

Flask (Backend API)

YOLOv8 (Object Detection Model)

Roboflow API (Model Deployment)

Google ML Kit (Text Recognition, OCR)

Text-to-Speech (TTS) 

ğŸ“š How It Works
User opens the app and selects a feature (Currency, Object, Color, Document).

The app captures real-time camera input.

AI models (YOLOv8/Roboflow/ML Kit) process the frame.

Results are spoken aloud using Text-to-Speech for easy understanding.

Users can navigate using simple gestures and receive voice feedback.


